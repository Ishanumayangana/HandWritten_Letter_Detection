{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h19MpV3KRk9v"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXXRV2NuSBzC",
        "outputId": "5536dabd-c06e-48ca-e676-6da7585a861e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4604127.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 130607.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1276646.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5148791.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0XESAfTSpYO",
        "outputId": "6c084547-97e3-492b-8d82-9db72f5e0d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QewlpyMaSvDu",
        "outputId": "3c1a2c0d-8267-42e0-f3b4-e88473f4816c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igrhO2gwS0w8",
        "outputId": "460c65e3-c2cb-44ee-b778-12b73c19e348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orwamNV8S6e1",
        "outputId": "8ce9f473-0615-48c4-eeed-e2196c597c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX_NLufATGzG",
        "outputId": "0ce58683-279f-48a7-aaae-7ed991543527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2KvFLVTTOyu",
        "outputId": "5198a907-d484-4a5a-b744-5540156203f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loaders = {\n",
        "\n",
        "           'train' : DataLoader(train_data,\n",
        "                                batch_size = 100,\n",
        "                                shuffle = True,\n",
        "                                num_workers=1),\n",
        "\n",
        "           'test' : DataLoader(test_data,\n",
        "                                batch_size = 100,\n",
        "                                shuffle = True,\n",
        "                                num_workers=1),\n",
        "}"
      ],
      "metadata": {
        "id": "wKz80ogmTWzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF9AGHVgUlT_",
        "outputId": "7939b29f-d89f-456d-e962-e71fc8a77bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7862bca98bb0>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7862bca9ac20>}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xpDtWw6mUsjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loaders['test']:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'].dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jm1WoZLLXxm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de2I6BNYtrSk",
        "outputId": "a16d7dcf-adb8-49d2-e265-4d8f2216ed92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301424\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.286220\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.185289\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.021500\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.913870\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.872194\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.858831\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.711695\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.702943\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.776361\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.776925\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.705318\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.708898\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.684004\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.654058\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.650853\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.609443\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.684822\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.700129\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.616662\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.636460\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.690415\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.573655\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 1.590898\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.661876\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.600621\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.642922\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.635239\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.535303\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.568590\n",
            "\n",
            "Test set: Average loss: 0.0153, Accuracy: 9321/10000 (93%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.594497\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.658283\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.594077\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.672019\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.548499\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.581128\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.581327\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.627936\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.585370\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.589296\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.593703\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.545195\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.626307\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.624095\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.540617\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.538265\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.553154\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.561233\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.580635\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.612585\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.568820\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.589458\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.550378\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.606598\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.519860\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.573454\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.529332\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.535492\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.527053\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.550037\n",
            "\n",
            "Test set: Average loss: 0.0151, Accuracy: 9526/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.520343\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.527685\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.563098\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.547612\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.559204\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.537343\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.552854\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.527893\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.586011\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.570264\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.535819\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.539308\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.577074\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.540687\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.560996\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.604427\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.593812\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.555484\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.574539\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.589295\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.541345\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.534741\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.534639\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.521549\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.537064\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.558893\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.519451\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.548087\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.562256\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.622118\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy: 9625/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.518620\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.582638\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.535710\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.541653\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.554149\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.530229\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.593480\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.540434\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.573609\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.600456\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.533312\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.516510\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.515304\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.537911\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.557119\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.562409\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.584496\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.568449\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.543369\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.559874\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.546184\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.534117\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.519504\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 1.529422\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.543221\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 1.515191\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 1.552682\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 1.517129\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 1.558386\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 1.565048\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy: 9644/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.531550\n",
            "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 1.585789\n",
            "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 1.587575\n",
            "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 1.547394\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 1.536046\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 1.513719\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 1.538249\n",
            "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 1.557174\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.538506\n",
            "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 1.565073\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.555265\n",
            "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 1.514301\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.562866\n",
            "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 1.503909\n",
            "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 1.551111\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 1.526121\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.536375\n",
            "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 1.517227\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 1.496354\n",
            "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 1.538635\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.547728\n",
            "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 1.544380\n",
            "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 1.564293\n",
            "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 1.552058\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.528946\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 1.575683\n",
            "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 1.518535\n",
            "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 1.519313\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 1.590594\n",
            "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 1.568306\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9687/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.542390\n",
            "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 1.525485\n",
            "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 1.527750\n",
            "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 1.520127\n",
            "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 1.539998\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 1.530964\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 1.518995\n",
            "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 1.527735\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.518411\n",
            "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 1.546772\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 1.537977\n",
            "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 1.539243\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 1.560462\n",
            "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 1.540864\n",
            "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 1.520532\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 1.554708\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.523233\n",
            "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 1.532161\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 1.549368\n",
            "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 1.528388\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 1.488078\n",
            "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 1.550514\n",
            "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 1.561547\n",
            "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 1.593236\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 1.497940\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 1.532983\n",
            "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 1.532659\n",
            "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 1.508707\n",
            "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 1.597132\n",
            "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 1.535483\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9710/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.561208\n",
            "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 1.520974\n",
            "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 1.549816\n",
            "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 1.521393\n",
            "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 1.526410\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 1.562692\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 1.544877\n",
            "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 1.522190\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.476887\n",
            "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 1.550567\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 1.508181\n",
            "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 1.568508\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 1.511856\n",
            "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 1.493728\n",
            "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 1.524436\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 1.503632\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.529567\n",
            "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 1.553006\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 1.543401\n",
            "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 1.520273\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 1.531294\n",
            "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 1.512883\n",
            "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 1.498663\n",
            "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 1.545762\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 1.538944\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 1.545391\n",
            "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 1.520795\n",
            "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 1.554017\n",
            "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 1.527493\n",
            "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 1.508331\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.516228\n",
            "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 1.478542\n",
            "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 1.508810\n",
            "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 1.516870\n",
            "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 1.525631\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 1.502283\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 1.509208\n",
            "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 1.493138\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.540450\n",
            "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 1.548579\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 1.516814\n",
            "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 1.512033\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 1.490363\n",
            "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 1.520474\n",
            "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 1.538274\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 1.517845\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.519529\n",
            "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 1.511565\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 1.543798\n",
            "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 1.531296\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.547210\n",
            "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 1.502633\n",
            "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 1.527481\n",
            "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 1.549217\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 1.538593\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 1.521120\n",
            "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 1.525028\n",
            "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 1.520115\n",
            "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 1.521811\n",
            "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 1.523696\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9744/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.546460\n",
            "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 1.519475\n",
            "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 1.512193\n",
            "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 1.546157\n",
            "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 1.523155\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 1.531593\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 1.519963\n",
            "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 1.516255\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.540400\n",
            "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 1.534991\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 1.551995\n",
            "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 1.537083\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 1.537256\n",
            "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 1.554547\n",
            "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 1.515549\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 1.524382\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.537928\n",
            "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 1.486059\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 1.508100\n",
            "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 1.496904\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 1.534590\n",
            "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 1.520111\n",
            "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 1.560269\n",
            "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 1.547777\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 1.497298\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 1.527417\n",
            "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 1.509453\n",
            "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 1.503606\n",
            "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 1.519869\n",
            "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 1.511090\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9756/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.533283\n",
            "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 1.531014\n",
            "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 1.523472\n",
            "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 1.551084\n",
            "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 1.509702\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 1.541395\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 1.511328\n",
            "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 1.501036\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 1.490693\n",
            "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 1.527398\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 1.501157\n",
            "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 1.518544\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 1.510069\n",
            "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 1.528777\n",
            "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 1.529639\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 1.507253\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.516821\n",
            "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 1.495475\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 1.524068\n",
            "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 1.486395\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 1.493857\n",
            "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 1.483285\n",
            "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 1.521761\n",
            "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 1.576999\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 1.568699\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 1.532680\n",
            "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 1.534912\n",
            "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 1.521060\n",
            "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 1.498265\n",
            "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 1.495944\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9757/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvjVNx_PvHTv",
        "outputId": "77ea0b57-69de-4cee-a39c-3073276a857b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model.eval()\n",
        "data, target = test_data[5]\n",
        "data = data.unsqueeze(0).to(device)\n",
        "output = model(data)\n",
        "prediction = output.argmax(dim=1,keepdim=True).item()\n",
        "print(f'Prediction : {prediction}')\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap= 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lnef2-xdwZ_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "7c8bf6ca-ca10-43cc-9519-f9e3b621f9b3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction : 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hieyzzCsyEDr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}